# Andrew Ng机器学习笔记

## 监督学习

训练数据有明确标签

### 分类

- 回归问题（拟合）
- 分类问题（分块）

## 无监督学习

训练数据无明确标签

聚类算法（新闻分类）

- 管理计算机集群
- 社交网络分析
- 市场分割
- 天文数据分析

## 模型描述

`m:样本数量` `x:输入（特征）` `y:输出（预测目标变量）` `(x,y):一个训练样本` `(x^(i),y^(i)):第i个训练样本` `h:假设函数` 

单变量线性回归

## 代价函数

### 数学定义

![1602306715172](image/1602306715172.png)

`θi:模型参数` 

![1602306963193](image/1602306963193.png)

![1602308775526](image/1602308775526.png)

式1：

$$
min_{\theta_0\theta_1}{{1}\over{2m}}\displaystyle \sum^{m}_{i=1}{(h_0(x^i)-y^i)^2}
$$

令式2：

$$
J(\theta_0,\theta_1)={{1}\over{2m}}\displaystyle \sum^{m}_{i=1}{(h_0(x^i)-y^i)^2}
$$

则式1可写为

$$
min_{\theta_0\theta_1}J(\theta_0,\theta_1)
$$

$J(\theta_0,\theta_1)$即为代价函数（lost function）或平方误差函数

![1602315144057](image/1602315144057.png)

等高线图（右图）

## 梯度下降

### 数学定义

问题概述

![1602316444056](image/1602316444056.png)


$$
\theta_j:=\theta_j-\alpha{{\delta} \over{\delta\theta_j}}J(\theta_0,\theta_1)
$$

$$
(for j=0 and j=1)
$$

`:=为赋值符号，将后项值赋予前项` `α:学习速率，控制梯度下降速率` 

算法实现时需要同时更新θ0和θ1

### 导数项

![202010101851](image/202010101851.JPG)

θ1均为增大

### α

太小：会导致找到最低点经历步数过多

太大：会导致可能无法收敛甚至发散

![202010101857](image/202010101857.JPG)

梯度下降中会自动在接近最低点的地方减小学习速率的值

### 线性回归的梯度下降

用梯度下降处理线性回归的代价函数

![202010182242](image/202010182242.JPG)

## 矩阵和向量

矩阵：由数字组成的矩形阵列。

向量：特殊的矩阵（只有一列）。

### 加法和标量乘法

矩阵加法：每个元素逐个相加。（只能维度相同的两个矩阵相加）

矩阵乘法：a行b列的矩阵A与b行n列的矩阵B相乘得到的矩阵X

- - X：a行n列，元素为A的第i行的各个元素和B的第i列的各个元素依次相乘再相加

![202011060008](image/202011060008.JPG)

![202011052357](image/202011052357.JPG)

![202011052353](image/202011052353.JPG)

[^预测房子的价格1]: 使用矩阵向量乘法使计算机更好的运算

![202011060000](image/202011060000.JPG)

[^预测房子的价格2]: 使用矩阵乘法使计算机更好的运算

### 矩阵乘法特征

有矩阵A和矩阵B

$A\times B \neq B\times A$ 

$(A\times B )\times C= B\times (A\times C)$ 

#### 单位矩阵

n x n矩阵，对角线元素是1，其余皆为0，记作$I_{n\times n}$

特性：对于任意的矩阵A

$A\cdot I = I\cdot A=A$ 

$A\times I = I\times A$

### 矩阵的逆和转置

#### 逆矩阵

只有m x m的矩阵（方阵 square matrix）才有逆矩阵

$A\times A^{-1} = A^{-1}\times A=I$

用pytorch求矩阵的逆：

```python
import torch

# matrix inverse
def invmat():
    a = torch.rand(3, 3)
    b = torch.inverse(a)
    print('a =', a)
    print('a\'s inverse matrix is:\n', b)

if __name__ == '__main__':
    print('matrix inverse')
    invmat()
```

结果：

```python
matrix inverse
a = tensor([[0.3769, 0.0635, 0.6297],
        [0.7425, 0.3456, 0.7372],
        [0.5285, 0.6245, 0.9408]])
a's inverse matrix is:
 tensor([[-1.2713,  3.1347, -1.6055],
        [-2.9043,  0.2050,  1.7833],
        [ 2.6419, -1.8969,  0.7811]])

Process finished with exit code 0
```
