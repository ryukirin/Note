# 吴恩达机器学习笔记

## 监督学习

训练数据有明确标签

### 分类

- 回归问题（拟合）
- 分类问题（分块）

## 无监督学习

训练数据无明确标签

聚类算法（新闻分类）

- 管理计算机集群
- 社交网络分析
- 市场分割
- 天文数据分析

## 模型描述

`m:样本数量` `x:输入（特征）` `y:输出（预测目标变量）` `(x,y):一个训练样本` `(x^(i),y^(i)):第i个训练样本` `h:假设函数` 

单变量线性回归

## 代价函数

### 数学定义

![1602306715172](image/1602306715172.png)

`θi:模型参数` 

![1602306963193](image/1602306963193.png)

![1602308775526](image/1602308775526.png)

式1：

$$
min_{\theta_0\theta_1}{{1}\over{2m}}\displaystyle \sum^{m}_{i=1}{(h_0(x^i)-y^i)^2}
$$

令式2：

$$
J(\theta_0,\theta_1)={{1}\over{2m}}\displaystyle \sum^{m}_{i=1}{(h_0(x^i)-y^i)^2}
$$

则式1可写为

$$
min_{\theta_0\theta_1}J(\theta_0,\theta_1)
$$

$J(\theta_0,\theta_1)$即为代价函数（lost function）或平方误差函数

![1602315144057](image/1602315144057.png)

等高线图（右图）

## 梯度下降

### 数学定义

问题概述

![1602316444056](image/1602316444056.png)


$$
\theta_j:=\theta_j-\alpha{{\delta} \over{\delta\theta_j}}J(\theta_0,\theta_1)
$$

$$
(for j=0 and j=1)
$$

`:=为赋值符号，将后项值赋予前项` `α:学习速率，控制梯度下降速率` 

算法实现时需要同时更新θ0和θ1

### 导数项

![202010101851](image/202010101851.JPG)

θ1均为增大

### α

太小：会导致找到最低点经历步数过多

太大：会导致可能无法收敛甚至发散

![202010101857](image/202010101857.JPG)

梯度下降中会自动在接近最低点的地方减小学习速率的值

### 线性回归的梯度下降

用梯度下降处理线性回归的代价函数

![202010182242](image/202010182242.JPG)

## 矩阵和向量

矩阵：由数字组成的矩形阵列。

向量：特殊的矩阵（只有一列）。

### 加法和标量乘法

矩阵加法：每个元素逐个相加。（只能维度相同的两个矩阵相加）

矩阵乘法：a行b列的矩阵A与b行n列的矩阵B相乘得到的矩阵X

- - X：a行n列，元素为A的第i行的各个元素和B的第i列的各个元素依次相乘再相加

例$\left[ \begin{matrix} 1 & 2 &1 & 5 \\ 0 & 3 & 0 &4 \\ -1& -2 & 0 & 0\end{matrix} \right]\left[\begin{matrix}1\\3\\2\\1\end{matrix}\right]=$$\left[\begin{matrix}1*1+2*3+1*2+5*1\\0*1+3*3+0*2+4*1\\-1*1+-2*3+0*2+0*1\end{matrix}\right]=$ $\left[\begin{matrix}14\\13\\-7\end{matrix}\right]$

![202011052357](image/202011052357.JPG)

![202011052353](image/202011052353.JPG)

[^预测房子的价格1]: 使用矩阵向量乘法使计算机更好的运算

![202011060000](image/202011060000.JPG)

[^预测房子的价格2]: 使用矩阵乘法使计算机更好的运算
